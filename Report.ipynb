{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  Predict Severity of Car Accident </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "This report is part of the __Applied Data Science Capstone__ project of the IBM Data Science Course. The aim of this project is to review what we have learned by solving a data analytic problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Background\n",
    "Traffic accidents have become an increasingly important issue threatening people's public safety. In some cases, due to the lag of information, rescue organizations cannot understand the details of the accident in time, more and more vehicles are congested on the road, and the situation is getting worse...\n",
    "Therefore, if we can predict the severity of the accident based on the existing relevant data (such as road conditions, weather, etc.), it will help to make corresponding preparations when the accident occurs and buy time for the next action. Real-time reminders of traffic accident predictions can also help alleviate traffic pressure.\n",
    "## 1.2 Problem\n",
    "In this project we will predict the severity of an accident given the relative data like weather, road condition, etc.\n",
    "\n",
    "## 1.3 Interest\n",
    "The stakeholder of this project can be drivers who can use the prediction to get more careful o the traffic emergency  department to get more prepared for the possible accident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Acquisition\n",
    "I use the dataset [National Collision Database](https://open.canada.ca/data/en/dataset/1eb9eba7-71d1-4b30-9fb1-30cbdab7e63a) which is a database containing all police-reported motor vehicle collisions on public roads in Canada. Selected variables (data elements) relating to fatal and injury collisions for the collisions from 1999 to 2017. The data can be found [here](https://opendatatc.blob.core.windows.net/opendatatc/NCDB_1999_to_2017.csv) and the data dictionary [here](https://opendatatc.blob.core.windows.net/opendatatc/NCDB_Data_Dictionary.docx)\n",
    "\n",
    "Our object is to predict the severity of collision from public data like road condition, weather, traffic control, etc. We will use the following fields:\n",
    "\n",
    "| Field          | Description                              |\n",
    "|----------------|:-----------------------------------------|\n",
    "| C_WDAY         | WDay of week                             |\n",
    "| C_SEV          | Collision severity                       |\n",
    "| C_VEHS         | Number of vehicles involved in collision |\n",
    "| C_CONF         | Collision configuration                  |\n",
    "| C_RCFG         | Roadway configuration                    |\n",
    "| C_WTHR         | Weather condition                        |\n",
    "| C_RSUR         | Road surface                             |\n",
    "| C_RALN         | Road alignment                           |\n",
    "| C_TRAF         | Traffic control                          |\n",
    "\n",
    "The dependent variable is __C_SEV__, and the rest is independent variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Data Cleaning\n",
    "#### Identify and handle missing values\n",
    "In the dataset, missing data comes with \"Q\",\"U\",\"X\",\"QQ\",\"UU\" or \"XX\". We replace them with NaN (Not a Number), which is Python's default missing value marker, for reasons of computational speed and convenience.\n",
    "As the number of missing value rows is not significant, we can simplly drop these rows.\n",
    "#### Resampling\n",
    "We can see that this is an imbalanced dataset, so we need to resample it first.\n",
    "\n",
    "C_SEV  | Counts\n",
    "---- | ----\n",
    "2 | 4518716\n",
    "1 | 79445\n",
    "\n",
    "A widely adopted technique for dealing with highly unbalanced datasets is called __resampling__. It consists of removing samples from the majority class (under-sampling) and / or adding more examples from the minority class (over-sampling).\n",
    "\n",
    "<img src=\"images/resampling.png\" alt=\"Drawing\" style=\"width: 550px;\"/>\n",
    "\n",
    "In this project, as we have a large dataset of each class, we use the __Random under-sampling__ method. \n",
    "\n",
    "After resampling, the dataset get balanced.\n",
    "\n",
    "<img src=\"images/balanced-class.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "#### Correct data format\n",
    "As we can see that only the variable *C_VEHS* is a continuous numerical variable, the others are all categorical data. So we need to change to the proper type to avoid problems in the future.\n",
    "\n",
    "#### Binning Data\n",
    "The field __C_CONF__ has too many values, we will bin the values in 4 groups according to there description in data dictionary.\n",
    "\n",
    "|value|description|\n",
    "|-----|:---------|\n",
    "|01-06| Single Vehicle in Motion|\n",
    "|21-25| Two Vehicles in Motion - Same Direction of Travel|\n",
    "|31-36| Two Vehicles in Motion - Different Direction of Travel|\n",
    "|41| Two Vehicles - Hit a Parked Motor Vehicle|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methodology\n",
    "### 3.1 Exploratory Data Analysis\n",
    "\n",
    "Lets look at the relation between individual feature and the severity using Visualization.\n",
    "\n",
    "#### Number of vehicles involved VS severity of collision\n",
    "![image](images/01-vehs.png)\n",
    "\n",
    "#### Day of week VS severity of collision\n",
    "![image](images/02-wday.png)\n",
    "As we can see that the day of week doesn't affact much on the severity.\n",
    "\n",
    "#### Type of Collision VS severity of collision\n",
    "![image](images/03-conf.png)\n",
    "\n",
    "#### Type of Roadway Configuration VS severity of collision\n",
    "![image](images/04-rcfg.png)\n",
    "\n",
    "#### Weather condition VS severity of collision\n",
    "![image](images/05-wthr.png)\n",
    "\n",
    "#### Road surface VS severity of collision\n",
    "![image](images/06-rsur.png)\n",
    "\n",
    "#### Road alignment VS severity of collision\n",
    "![image](images/08-raln.png)\n",
    "\n",
    "#### Traffic control VS severity of collision\n",
    "![image](images/07-traf.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feature Selection\n",
    "\n",
    "<h3>Conclusion: Important Variables</h3>\n",
    "<p>We now have a better idea of what our data looks like and which variables are important to take into account when predicting the severity of an accident. We have narrowed it down to the following variables:</p>\n",
    "\n",
    "Continuous numerical variables:\n",
    "<ul>\n",
    "    <li>C_VEHS</li>  \n",
    "</ul>\n",
    "    \n",
    "Categorical variables:\n",
    "<ul>\n",
    "    <li>C_WDAY</li>\n",
    "    <li>C_CONF</li>\n",
    "    <li>C_RCFG</li>\n",
    "    <li>C_WTHR</li>\n",
    "    <li>C_RSUR</li>\n",
    "    <li>C_RALN</li>\n",
    "    <li>C_TRAF</li>\n",
    "</ul>\n",
    "\n",
    "### 3.3 Convert Categorical features to numerical values\n",
    "#### One Hot Encoding\n",
    "In this part we use one hot encoding to convert categorical data to numerical values. \n",
    "\n",
    "Features after one hot encoding:\n",
    "\n",
    "- 'C_VEHS', \n",
    "\n",
    "- '1-Vehicle', '2-Vehicles-Same', '2-Vehicles-Different','2-Vehicles-Parked', \n",
    "\n",
    "- 'Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday', 'Saturday', 'Sunday', \n",
    "\n",
    "- 'Non-intersection','intersection-2public', 'intersection-parking', 'railroad-crossing','Bridge-overpass-viaduct', 'Tunnel-underpass', 'Passing-climbing-lane','Ramp', 'Traffic-circle', 'Express-lane', \n",
    "\n",
    "- 'Clear-sunny','Overcast-cloudy-no-precipitation', 'Raining','Snowing-not-drifting-snow', 'Freezing-rain-sleet-hail',\n",
    "\n",
    "- 'Visibility-limitation', 'Strong wind', 'Dry-normal', 'Wet', 'Snow','Slush-wet-snow', 'Icy', 'Sand-gravel-dirt', 'Muddy', 'Oil', 'Flooded',\n",
    "\n",
    "- 'Straight-level', 'Straight-gradient', 'Curved-level','Curved-gradient', 'Top-hill-gradient', 'Bottom-hill-gradient',\n",
    "\n",
    "- 'fully-operational', 'flashing-mode', 'Stop-sign', 'Yield-sign','Warning-sign', 'Pedestrian-crosswalk', 'Police-officer','School-guard', 'school-crossing', 'Reduced-speed-zone','No-passing-sign', 'Markings-on-the-road','School-bus-stopped-flashing', 'Railway-crossing-signals-or-gate','Railway-crossing-signs', 'Control-device-not-specified','No-control-present'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4  Clasification Modeling and Evaluation\n",
    "The dependent variable is a labeled data with binary values, so we can easily think of clasification models.\n",
    "\n",
    "We will split the processed dataset into training and test, and we use the training dataset to build an accurate model. Then use the test set to report the accuracy of the model You should use the following algorithm:\n",
    "\n",
    "- K Nearest Neighbor(KNN) (we need to use only train set to find the best k value)\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "I observed that the quantity of data hasn't make difference on the accuracy.\n",
    "For example, when 20% of the rebalanced set was used. The evaluation metrics:\n",
    "\n",
    "| Algorithm          | Jaccard | F1-score | LogLoss |\n",
    "|--------------------|---------|----------|---------|\n",
    "| KNN                | 0.6645       | 0.6644        | NA      |\n",
    "| Decision Tree      | 0.6916       | 0.6905        | NA      |\n",
    "| SVM                | __0.7081__       | 0.7080        | NA      |\n",
    "| LogisticRegression | 0.7047       | 0.7047        | 0.57    |\n",
    "\n",
    "When we use 30% of the rebalanced set\n",
    "\n",
    "| Algorithm          | Jaccard | F1-score | LogLoss |\n",
    "|--------------------|---------|----------|---------|\n",
    "| KNN                | 0.6605       | 0.6604        | NA      |\n",
    "| Decision Tree      | 0.6932       | 0.6911        | NA      |\n",
    "| SVM                | __0.7063__       | 0.7063        | NA      |\n",
    "| LogisticRegression | 0.7057       | 0.7057        | 0.58    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "In this project I've only tried the most used classfication models. \n",
    "However, we have more work to do in the part of features selection. It could be improved in several ways, such as:\n",
    "- [Feature importance scores](https://machinelearningmastery.com/calculate-feature-importance-with-python/) can provide insight into the dataset. The relative scores can highlight which features may be most relevant to the target, and the converse, which features are the least relevant. This may be interpreted by a domain expert and could be used as the basis for gathering more or different data.\n",
    "- [Search for Categorical Correlation](https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9)\n",
    "\n",
    "- [Find Correlation among multiple categorical variables](https://stackoverflow.com/questions/48035381/correlation-among-multiple-categorical-variables-pandas)\n",
    "\n",
    "On the other hand, more features should be included like the visibility and this will contribute more information to the prediction and help the build better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "In this project I have applied what I have learned in this course. Following the principle methodology of data analysis and trying to find a proper model to predict the severity of a traffic accident.\n",
    "I have done the part of data acquisition, data pre-prossing and explotory data visualization, and finally to find the best classifier.\n",
    "However, I've encontered problems of feature selection on categorical features and the reduction of them. In this respect, we can try the method mentioned in the __Discussion__ section in the future and build a better model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
